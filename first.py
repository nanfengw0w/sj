from github import Github
from github import Auth
import pandas as pd
import time
from dotenv import load_dotenv
import os
import matplotlib.pyplot as plt
import seaborn as sns

load_dotenv()
GITHUB_TOKEN = "è¿™é‡Œå¡«å…¥ä½ è‡ªå·±çš„GitHubä»¤ç‰Œ"
auth = Auth.Token(GITHUB_TOKEN)
g = Github(auth=auth)
repo = g.get_repo("pandas-dev/pandas")
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False

# æ•°æ®é‡‡é›†
print("å¼€å§‹çˆ¬å–çº¯Issueæ•°æ®")

def crawl_pure_issues(repo, total_limit=1000):

    pure_issues_list = []
    issues_paginator = repo.get_issues(state="closed")  # çˆ¬å–å·²å¤„ç†çš„çº¯Issue
    
    for issue in issues_paginator:
        # è¿‡æ»¤PR
        if issue.pull_request:
            continue
        if len(pure_issues_list) >= total_limit:
            break
        issues_dict = {
            "issue_number": issue.number,
            "title": issue.title,
            "content": issue.body if issue.body else "",
            "labels": [label.name for label in issue.labels],
            "create_time": issue.created_at,
            "close_time": issue.closed_at,
            "comments_count": issue.comments,
            "state": issue.state
        }
        pure_issues_list.append(issues_dict)
        time.sleep(0.1)  # é¿å…APIé™æµ
        if len(pure_issues_list) % 100 == 0:
            print(f"å·²çˆ¬å–{len(pure_issues_list)}æ¡Issue")
    
    return pd.DataFrame(pure_issues_list)

def crawl_contributors(repo, top_n=50):
    contributors_list = []
    contributors = repo.get_contributors()
    count = 0
    for contributor in contributors:
        if count >= top_n:
            break
        contributors_dict = {
            "user_id": contributor.id,
            "user_name": contributor.login,
            "contributions": contributor.contributions,
            "email": contributor.email if contributor.email else "",
            "github_url": contributor.html_url
        }
        contributors_list.append(contributors_dict)
        count += 1
    return pd.DataFrame(contributors_list)

# æ‰§è¡Œçˆ¬å–
issues_raw_df = crawl_pure_issues(repo, total_limit=1000)
contributors_raw_df = crawl_contributors(repo)
# è¾“å‡ºåŸå§‹æ•°æ®
issues_raw_df.to_csv("github_pure_issues_raw.csv", index=False, encoding="utf-8-sig")
contributors_raw_df.to_csv("github_contributors_raw.csv", index=False, encoding="utf-8-sig")

print("===== çº¯IssueåŸå§‹æ•°æ®å·²è¾“å‡ºä¸ºCSV =====")
print(f"çˆ¬å–çš„çº¯Issueæ•°æ®å‰5è¡Œï¼š\n{issues_raw_df.head()}")
print(f"æœ¬æ¬¡çˆ¬å–çº¯Issueæ€»æ•°ï¼š{len(issues_raw_df)}")

# æ•°æ®é¢„å¤„ç†ï¼ˆè¿‡æ»¤æ— æ ‡ç­¾+æ¸…æ´—ï¼‰
print("\n===== å¼€å§‹æ•°æ®é¢„å¤„ç† =====")

issues_clean_df = issues_raw_df.copy()
# å»é‡
issues_clean_df = issues_clean_df.drop_duplicates(subset="issue_number", keep="first")
# åˆ ç©ºå†…å®¹Issue
issues_clean_df = issues_clean_df[issues_clean_df["content"].str.strip() != ""]
# å‰”é™¤å¼‚å¸¸
issues_clean_df = issues_clean_df[~((issues_clean_df["close_time"].isna()) & (issues_clean_df["state"] == "closed"))]
# æ—¶é—´æ ¼å¼ç»Ÿä¸€
issues_clean_df["create_time"] = pd.to_datetime(issues_clean_df["create_time"]).dt.strftime("%Y-%m-%d %H:%M:%S")
issues_clean_df["close_time"] = pd.to_datetime(issues_clean_df["close_time"]).dt.strftime("%Y-%m-%d %H:%M:%S")

# ç»Ÿè®¡çº¯Issueçš„æ ‡ç­¾åˆ†å¸ƒ
print("\nğŸ“Š çº¯Issueæ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡ï¼š")
no_label_count = len(issues_clean_df[issues_clean_df["labels"].apply(lambda x: len(x) == 0)])
has_label_count = len(issues_clean_df) - no_label_count
print(f"é¢„å¤„ç†åçº¯Issueæ€»æ•°ï¼š{len(issues_clean_df)}")
print(f"å…¶ä¸­ï¼šæ— æ ‡ç­¾={no_label_count}æ¡ï¼Œæœ‰æ ‡ç­¾={has_label_count}æ¡")

# è´¡çŒ®è€…æ•°æ®å¡«å……
contributors_clean_df = contributors_raw_df.copy()
contributors_clean_df["email"] = contributors_clean_df["email"].fillna("æœªå…¬å¼€")

issues_clean_df.to_csv("github_pure_issues_clean.csv", index=False, encoding="utf-8-sig")
contributors_clean_df.to_csv("github_contributors_clean.csv", index=False, encoding="utf-8-sig")


# è´¡çŒ®è€…åˆ†æ
contributors_clean_df = contributors_clean_df.sort_values(by="contributions", ascending=False)
top10_contrib = contributors_clean_df.head(10)["contributions"].sum()
total_contrib = contributors_clean_df["contributions"].sum()
top10_ratio = (top10_contrib / total_contrib) * 100

contributors_analysis_df = contributors_clean_df.copy()
contributors_analysis_df["contribution_ratio"] = (contributors_analysis_df["contributions"] / total_contrib) * 100
contributors_analysis_df.to_csv("github_contributors_analysis.csv", index=False, encoding="utf-8-sig")
print(f"\nğŸ‘¥ è´¡çŒ®è€…åˆ†æç»“æœï¼š")
print(f"å‰10ä½æ ¸å¿ƒè´¡çŒ®è€…æäº¤å æ¯”ï¼š{top10_ratio:.1f}%")

# Issueæ ‡ç­¾åˆ†æ
filtered_issues = issues_clean_df[issues_clean_df["labels"].apply(lambda x: len(x) > 0)]
# å±•å¼€æ ‡ç­¾
labels_flat = []
for labels in filtered_issues["labels"]:
    labels_flat.extend(labels)
labels_count = pd.Series(labels_flat).value_counts()
top_n = 10
auto_core_labels = labels_count.head(top_n).index.tolist()

print(f"\næå–çš„Top{top_n}é«˜é¢‘ä¸šåŠ¡æ ‡ç­¾\n{auto_core_labels}")

# ç»Ÿè®¡æ ‡ç­¾å æ¯”
core_labels_count = labels_count[auto_core_labels].reset_index()
core_labels_count.columns = ["label_type", "count"]
core_labels_count["ratio"] = (core_labels_count["count"] / core_labels_count["count"].sum()) * 100
core_labels_count.to_csv("github_issues_labels_analysis.csv", index=False, encoding="utf-8-sig")
print(f"\nçº¯IssueTop{top_n}ä¸šåŠ¡æ ‡ç­¾åˆ†æç»“æœï¼š\n{core_labels_count}")

# Issueè§£å†³æ—¶é•¿
closed_issues = filtered_issues[filtered_issues["state"] == "closed"].copy()
closed_issues["create_time"] = pd.to_datetime(closed_issues["create_time"])
closed_issues["close_time"] = pd.to_datetime(closed_issues["close_time"])
closed_issues["resolve_days"] = (closed_issues["close_time"] - closed_issues["create_time"]).dt.days

resolve_time_by_label = []
for label in auto_core_labels:
    label_issues = closed_issues[closed_issues["labels"].apply(lambda x: label in x)]
    avg_days = label_issues["resolve_days"].mean() if len(label_issues) > 0 else 0.0
    resolve_time_by_label.append({"label_type": label, "avg_resolve_days": round(avg_days, 1)})

resolve_time_df = pd.DataFrame(resolve_time_by_label)
resolve_time_df.to_csv("github_issues_resolve_time.csv", index=False, encoding="utf-8-sig")
print(f"\nâ±çº¯IssueTop{top_n}ä¸šåŠ¡æ ‡ç­¾è§£å†³æ—¶é•¿åˆ†æç»“æœï¼š\n{resolve_time_df}")

# æ•°æ®å¯è§†åŒ–
print("\n===== å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ =====")

# å›¾è¡¨1ï¼šè´¡çŒ®è€…å æ¯”é¥¼å›¾
pie_data = [top10_contrib, total_contrib - top10_contrib]
pie_labels = [f"å‰10ä½è´¡çŒ®è€…\n({top10_ratio:.1f}%)", f"å…¶ä»–40ä½\n({100-top10_ratio:.1f}%)"]
plt.figure(figsize=(8, 8))
plt.pie(pie_data, labels=pie_labels, autopct="%1.1f%%", colors=["#ff7f0e", "#2ca02c"])
plt.title("pandasä»“åº“è´¡çŒ®è€…æäº¤å æ¯”", fontsize=14)
plt.tight_layout()
plt.savefig("contributors_contrib_ratio.png", dpi=300)

# å›¾è¡¨2ï¼šTop10ä¸šåŠ¡æ ‡ç­¾åˆ†å¸ƒ
plt.figure(figsize=(12, 6))
sns.barplot(data=core_labels_count, x="label_type", y="count", palette="Set2")
plt.title(f"pandasä»“åº“çº¯Issue Top{top_n}ä¸šåŠ¡æ ‡ç­¾åˆ†å¸ƒ", fontsize=14)
plt.xlabel("æ ‡ç­¾ç±»å‹")
plt.ylabel("æ•°é‡")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("issues_labels_dist.png", dpi=300)

print("\n å…¨æµç¨‹å®Œæˆï¼è¾“å‡ºæ–‡ä»¶æ¸…å•ï¼š")
print("ã€åŸå§‹æ•°æ®ã€‘ï¼šgithub_pure_issues_raw.csvã€github_contributors_raw.csv")
print("ã€é¢„å¤„ç†æ•°æ®ã€‘ï¼šgithub_pure_issues_clean.csvã€github_contributors_clean.csv")
print("ã€åˆ†æç»“æœã€‘ï¼šgithub_contributors_analysis.csvã€github_issues_labels_analysis.csvã€github_issues_resolve_time.csv")
print("ã€å¯è§†åŒ–å›¾è¡¨ã€‘ï¼šcontributors_contrib_ratio.pngã€issues_labels_dist.png")